{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "删除V5,V9,V11,V17,V21,V22,V28\n",
    "\n",
    "先用Lasso做二次化的拟合，然后用随机森林做一次的拟合，然后融合。\n",
    "\n",
    "要删除每个模型的异常点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载数据，删除异常分布的特征\n",
    "#返回训练集的X，y和测试集test\n",
    "def load_data():\n",
    "    train = pd.read_csv('zhengqi_train.txt', sep='\\t')\n",
    "    test = pd.read_csv('zhengqi_test.txt', sep='\\t')\n",
    "    cols=['V5','V9','V11','V17','V21','V22','V28']\n",
    "    #['V5','V9','V11','V14','V17','V21','V22','V25','V26','V28','V32','V33','V34']\n",
    "    train = train.drop(cols, axis=1)\n",
    "    test = test.drop(cols, axis=1)\n",
    "    x_train = train.loc[:,'V0':'V37']\n",
    "    y_train = train['target']\n",
    "    return x_train, y_train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#输入模型，X，y，返回异常点的指标。\n",
    "def outliers(model, x, y, sigma=3):\n",
    "    model.fit(x,y)\n",
    "    y_pre=pd.Series(model.predict(x), index=y.index)\n",
    "    re=y-y_pre\n",
    "    mean_re=re.mean()\n",
    "    std_re =re.std()\n",
    "    z=(re-mean_re)/std_re\n",
    "    outliers=z[abs(z)>sigma].index\n",
    "    print(len(outliers),'outliers:')\n",
    "    print(outliers)\n",
    "    print()\n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#输入模型，备选参数，训练集，返回调参后的模型，并输出参数。\n",
    "def train_model(model, params, x_train, y_train):\n",
    "    gs=GridSearchCV(model, param_grid=params, scoring='neg_mean_squared_error',cv=4)\n",
    "    gs.fit(x_train, y_train)\n",
    "    model=gs.best_estimator_\n",
    "    score1=round(gs.best_score_, 4)\n",
    "    params1=gs.best_params_\n",
    "    print(model.__class__.__name__,':',score1,params1)\n",
    "    print()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#输入调参后的模型、测试集、训练集，返回预测值。\n",
    "def y_pre(model, test, x_train, y_train):\n",
    "    model.fit(x_train, y_train)\n",
    "    pre=model.predict(test)\n",
    "    p=pd.DataFrame(pre)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#删除异常点，返回训练集\n",
    "def del_outs(outs,x,y):\n",
    "    x=x.drop(outs)\n",
    "    y=y.drop(outs)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对特征进行二次多项式变换，返回训练集和测试集。\n",
    "def poly_features(x,t,deg=2):\n",
    "    poly=PolynomialFeatures(degree=deg)\n",
    "    x=pd.DataFrame(poly.fit_transform(x))\n",
    "    t=pd.DataFrame(poly.fit_transform(t))\n",
    "    return x, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################Lasso\n",
    "#第一次训练\n",
    "lasso_model=Lasso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 outliers:\n",
      "Int64Index([ 344,  401,  430,  843,  874,  884,  903,  909,  921, 1038, 1077,\n",
      "            1147, 1485, 1547, 1548, 1679, 1864, 1870, 1882, 1894, 1933, 2590,\n",
      "            2652, 2767, 2768, 2790, 2840],\n",
      "           dtype='int64')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train,test=load_data()\n",
    "x_train, test = poly_features(x_train, test, deg=2)\n",
    "outs=outliers(lasso_model, x_train, y_train)\n",
    "x_train,y_train=del_outs(outs,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso : -0.1291 {'alpha': 0.015000000000000003}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p={'alpha':np.arange(0.011, 0.020, 0.001)}\n",
    "\n",
    "lasso_model=train_model(lasso_model,p,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用训练后的模型来判断异常点，再第二次训练模型\n",
    "lasso_model=Lasso(alpha=0.015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 outliers:\n",
      "Int64Index([ 321,  344,  693,  776,  777, 1046, 1069, 1085, 1141, 1145, 1164,\n",
      "            1310, 1311, 1523, 1704, 1874, 1934, 1979, 2002, 2160, 2211, 2264,\n",
      "            2274, 2279, 2620, 2645, 2647, 2667, 2668, 2669, 2696, 2697, 2769,\n",
      "            2807, 2842, 2863],\n",
      "           dtype='int64')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train,test=load_data()\n",
    "x_train, test = poly_features(x_train, test, deg=2)\n",
    "outs=outliers(lasso_model, x_train, y_train)\n",
    "x_train,y_train=del_outs(outs,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso : -0.1067 {'alpha': 0.012}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p={'alpha':np.arange(0.005, 0.020, 0.001)}\n",
    "\n",
    "lasso_model=train_model(lasso_model,p,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lasso_pre=y_pre(lasso_model,test,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################RFR######\n",
    "rf_model=RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 outliers:\n",
      "Int64Index([  70,  321,  693,  715,  776,  805,  809, 1036, 1064, 1125, 1140,\n",
      "            1145, 1146, 1294, 1511, 1523, 1684, 1704, 1878, 1901, 1936, 1950,\n",
      "            2158, 2159, 2160, 2255, 2270, 2279, 2607, 2619, 2620, 2647, 2667,\n",
      "            2696, 2770, 2801, 2807],\n",
      "           dtype='int64')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train,test=load_data()\n",
    "outs=outliers(rf_model,x_train,y_train)\n",
    "x_train,y_train=del_outs(outs,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor : -0.1269 {'max_depth': 14, 'n_estimators': 140}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p={'n_estimators':range(120,150,10),\n",
    "    'max_depth':[None,11,12,13,14,],\n",
    "    #'n_estimators':[120],'max_depth':[13],\n",
    "    #'min_samples_split':range(6,12,1)\n",
    "  }\n",
    "\n",
    "rf_model=train_model(rf_model,p,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用训练后的模型来判断异常点，再第二次训练模型\n",
    "rf_model=RandomForestRegressor(max_depth=14, min_samples_split=6, n_estimators=140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 outliers:\n",
      "Int64Index([ 344,  348,  376,  419,  771,  776,  777,  843,  884, 1128, 1140,\n",
      "            1145, 1164, 1311, 1412, 1458, 1476, 1704, 1934, 2166, 2211, 2264,\n",
      "            2274, 2279, 2592, 2620, 2645, 2647, 2655, 2667, 2668, 2669, 2696,\n",
      "            2697, 2769, 2800, 2801, 2807, 2863],\n",
      "           dtype='int64')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train,test=load_data()\n",
    "outs=outliers(rf_model,x_train,y_train)\n",
    "x_train,y_train=del_outs(outs,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor : -0.1179 {'max_depth': 14, 'min_samples_split': 4, 'n_estimators': 110}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p={#'n_estimators':range(80,130,10),\n",
    "    #'max_depth':[None,11,12,13,14,15,],\n",
    "    'n_estimators':[110],\n",
    "    'max_depth':[14],\n",
    "    'min_samples_split':range(3,12,1)\n",
    "  }\n",
    "\n",
    "rf_model=train_model(rf_model,p,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_pre=y_pre(rf_model,test,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=0.7*Lasso_pre+0.3*RF_pre#0.1220"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.to_csv('average2.0.txt',sep='\\t',index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不删特征，用二次多项式化的Lasso+不二次化的ETR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_():\n",
    "    train = pd.read_csv('zhengqi_train.txt', sep='\\t')\n",
    "    test = pd.read_csv('zhengqi_test.txt', sep='\\t')\n",
    "    #cols=['V5','V9','V11','V17','V21','V22','V28']\n",
    "    #['V5','V9','V11','V14','V17','V21','V22','V25','V26','V28','V32','V33','V34']\n",
    "    #train = train.drop(cols, axis=1)\n",
    "    #test = test.drop(cols, axis=1)\n",
    "    x_train = train.loc[:,'V0':'V37']\n",
    "    y_train = train['target']\n",
    "    return x_train, y_train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################Lasso  二次\n",
    "lasso_model=Lasso(alpha=0.009)\n",
    "#lasso_model=Lasso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train,test=load_data_()\n",
    "x_train, test = poly_features(x_train, test, deg=2)\n",
    "outs=outliers(lasso_model, x_train, y_train)\n",
    "x_train,y_train=del_outs(outs,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p={'alpha':np.arange(0.005, 0.020, 0.001)}\n",
    "\n",
    "lasso_model=train_model(lasso_model,p,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lasso_pre=y_pre(lasso_model,test,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ETR\n",
    "et_model=ExtraTreesRegressor(max_depth=18,n_estimators=200,\n",
    "                             max_features=0.9,min_samples_split=5,min_samples_leaf=2)\n",
    "#et_model=ExtraTreesRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train,test=load_data_()\n",
    "outs=outliers(et_model,x_train,y_train)\n",
    "x_train,y_train=del_outs(outs,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p={\n",
    "#    'max_depth':range(16,20,1),'n_estimators':np.arange(180,230,10),\n",
    "    'max_depth':[19],'n_estimators':[200],\n",
    "    'max_features':[0.8,],'min_samples_split':range(2,8,1),'min_samples_leaf':range(1,7,1),\n",
    "#    'max_features':[0.7],'min_samples_split':[4],'min_samples_leaf':[2],\n",
    "  }\n",
    "\n",
    "et_model=train_model(et_model,p,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ETR_pre=y_pre(et_model,test,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=0.7*Lasso_pre+0.3*ETR_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.to_csv('average3.0.txt',sep='\\t',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
